{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPm05zUG+ZOaL118UuKEl7C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uEJ_7Oj5Yl_H","executionInfo":{"status":"ok","timestamp":1701350408766,"user_tz":-330,"elapsed":9123,"user":{"displayName":"Venkatesh Elangovan","userId":"12247996726828990634"}},"outputId":"6df60a3a-4ce8-4e53-b5c0-8f8c7d0f33ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-1k56o6jv\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-1k56o6jv\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4294 sha256=e2b8c6617a1649e47f139f74f70369a182a779727ec720a66b047a3c0ac60f02\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4bjvxh90/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n","created output directory at /content/src\n","Out bin /content/result.out\n"]}],"source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n","%load_ext nvcc_plugin"]},{"cell_type":"markdown","source":["16 and 8\n"],"metadata":{"id":"UfU_3GnvaEXh"}},{"cell_type":"code","source":["%%cu\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include <cuda.h>\n","#include <sys/time.h>\n","\n","__global__ void reduceUnrolling8 (int *g_idata, int *g_odata, unsigned int n)\n","{\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n","\n","    // unrolling 8\n","    if (idx + 7 * blockDim.x < n)\n","    {\n","        int a1 = g_idata[idx];\n","        int a2 = g_idata[idx + blockDim.x];\n","        int a3 = g_idata[idx + 2 * blockDim.x];\n","        int a4 = g_idata[idx + 3 * blockDim.x];\n","        int b1 = g_idata[idx + 4 * blockDim.x];\n","        int b2 = g_idata[idx + 5 * blockDim.x];\n","        int b3 = g_idata[idx + 6 * blockDim.x];\n","        int b4 = g_idata[idx + 7 * blockDim.x];\n","        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n","    }\n","\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n","    {\n","        if (tid < stride)\n","        {\n","            idata[tid] += idata[tid + stride];\n","        }\n","\n","        // synchronize within threadblock\n","        __syncthreads();\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n","}\n","__global__ void reduceUnrolling16 (int *g_idata, int *g_odata, unsigned int n)\n","{\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    unsigned int idx = blockIdx.x * blockDim.x * 16 + threadIdx.x;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x * 16;\n","\n","    // unrolling 16\n","    if (idx + 15 * blockDim.x < n)\n","    {\n","        int a1 = g_idata[idx];\n","        int a2 = g_idata[idx + blockDim.x];\n","        int a3 = g_idata[idx + 2 * blockDim.x];\n","        int a4 = g_idata[idx + 3 * blockDim.x];\n","        int b1 = g_idata[idx + 4 * blockDim.x];\n","        int b2 = g_idata[idx + 5 * blockDim.x];\n","        int b3 = g_idata[idx + 6 * blockDim.x];\n","        int b4 = g_idata[idx + 7 * blockDim.x];\n","        int c1 = g_idata[idx + 8 * blockDim.x];\n","        int c2 = g_idata[idx + 9 * blockDim.x];\n","        int c3 = g_idata[idx + 10 * blockDim.x];\n","        int c4 = g_idata[idx + 11 * blockDim.x];\n","        int d1 = g_idata[idx + 12 * blockDim.x];\n","        int d2 = g_idata[idx + 13 * blockDim.x];\n","        int d3 = g_idata[idx + 14 * blockDim.x];\n","        int d4 = g_idata[idx + 15 * blockDim.x];\n","        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4 + c1 + c2 + c3 + c4\n","                       + d1 + d2 + d3 + d4;\n","    }\n","\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n","    {\n","        if (tid < stride)\n","        {\n","            idata[tid] += idata[tid + stride];\n","        }\n","\n","        // synchronize within threadblock\n","        __syncthreads();\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n","}\n","\n","#ifndef _COMMON_H\n","#define _COMMON_H\n","\n","#define CHECK(call)                                                            \\\n","{                                                                              \\\n","    const cudaError_t error = call;                                            \\\n","    if (error != cudaSuccess)                                                  \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n","        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n","                cudaGetErrorString(error));                                    \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUBLAS(call)                                                     \\\n","{                                                                              \\\n","    cublasStatus_t err;                                                        \\\n","    if ((err = (call)) != CUBLAS_STATUS_SUCCESS)                               \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CUBLAS error %d at %s:%d\\n\", err, __FILE__,       \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CURAND(call)                                                     \\\n","{                                                                              \\\n","    curandStatus_t err;                                                        \\\n","    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUFFT(call)                                                      \\\n","{                                                                              \\\n","    cufftResult err;                                                           \\\n","    if ( (err = (call)) != CUFFT_SUCCESS)                                      \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CUFFT error %d at %s:%d\\n\", err, __FILE__,        \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUSPARSE(call)                                                   \\\n","{                                                                              \\\n","    cusparseStatus_t err;                                                      \\\n","    if ((err = (call)) != CUSPARSE_STATUS_SUCCESS)                             \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got error %d at %s:%d\\n\", err, __FILE__, __LINE__);   \\\n","        cudaError_t cuda_err = cudaGetLastError();                             \\\n","        if (cuda_err != cudaSuccess)                                           \\\n","        {                                                                      \\\n","            fprintf(stderr, \"  CUDA error \\\"%s\\\" also detected\\n\",             \\\n","                    cudaGetErrorString(cuda_err));                             \\\n","        }                                                                      \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","inline double seconds()\n","{\n","    struct timeval tp;\n","    struct timezone tzp;\n","    int i = gettimeofday(&tp, &tzp);\n","    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n","}\n","\n","#endif // _COMMON_H\n","\n","int main(int argc, char **argv)\n","{\n","    // set up device\n","    int dev = 0;\n","    cudaDeviceProp deviceProp;\n","    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","    printf(\"%s starting reduction at \", argv[0]);\n","    printf(\"device %d: %s \", dev, deviceProp.name);\n","    CHECK(cudaSetDevice(dev));\n","\n","    bool bResult = false;\n","\n","    // initialization\n","    int size = 1 << 24; // total number of elements to reduce\n","    printf(\"    with array size %d  \", size);\n","\n","    // execution configuration\n","    int blocksize = 512;   // initial block size\n","\n","    if(argc > 1)\n","    {\n","        blocksize = atoi(argv[1]);   // block size from command line argument\n","    }\n","\n","    dim3 block (blocksize, 1);\n","    dim3 grid  ((size + block.x - 1) / block.x, 1);\n","    printf(\"grid %d block %d\\n\", grid.x, block.x);\n","\n","    // allocate host memory\n","    size_t bytes = size * sizeof(int);\n","    int *h_idata = (int *) malloc(bytes);\n","    int *h_odata = (int *) malloc(grid.x * sizeof(int));\n","    int *tmp     = (int *) malloc(bytes);\n","\n","    // initialize the array\n","    for (int i = 0; i < size; i++)\n","    {\n","        // mask off high 2 bytes to force max number to 255\n","        h_idata[i] = (int)( rand() & 0xFF );\n","    }\n","\n","    memcpy (tmp, h_idata, bytes);\n","\n","    double iStart, iElapsunroll8,iElapsunroll16;\n","    int gpu_sum = 0;\n","\n","    // allocate device memory\n","    int *d_idata = NULL;\n","    int *d_odata = NULL;\n","    CHECK(cudaMalloc((void **) &d_idata, bytes));\n","    CHECK(cudaMalloc((void **) &d_odata, grid.x * sizeof(int)));\n","\n","    // kernel 1: reduceUnrolling8\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    CHECK(cudaDeviceSynchronize());\n","    iStart = seconds();\n","    reduceUnrolling8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaDeviceSynchronize());\n","    iElapsunroll8 = seconds() - iStart;\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"gpu Unrolling8  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n","           \"%d>>>\\n\", iElapsunroll8, gpu_sum, grid.x / 8, block.x);\n","\n","    for (int i = 0; i < grid.x / 16; i++) gpu_sum += h_odata[i];\n","// kernel 2: reduceUnrolling16\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    CHECK(cudaDeviceSynchronize());\n","    iStart = seconds();\n","    reduceUnrolling16<<<grid.x / 16, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaDeviceSynchronize());\n","    iElapsunroll16 = seconds() - iStart;\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 16 * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x / 16; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"gpu Unrolling16 elapsed %f sec gpu_sum: %d <<<grid %d block \"\n","           \"%d>>>\\n\", iElapsunroll16, gpu_sum, grid.x / 16, block.x);\n","\n","    // Determine the kernel with the least execution time\n","    if (iElapsunroll8< iElapsunroll16)\n","    {\n","        printf(\"reduceUnrolling8 has the least execution time.\\n\");\n","    }\n","    else if (iElapsunroll16 < iElapsunroll8)\n","    {\n","        printf(\"reduceUnrolling16 has the least execution time.\\n\");\n","    }\n","    else\n","    {\n","        printf(\"reduceUnrolling8 and reduceUnrolling16 have the same execution time.\\n\");\n","    }\n","    // free host memory\n","    free(h_idata);\n","    free(h_odata);\n","    // free device memory\n","    CHECK(cudaFree(d_idata));\n","    CHECK(cudaFree(d_odata));\n","    // reset device\n","    CHECK(cudaDeviceReset());\n","    return EXIT_SUCCESS;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4a2_PLtPYrAc","executionInfo":{"status":"ok","timestamp":1701350637231,"user_tz":-330,"elapsed":2068,"user":{"displayName":"Venkatesh Elangovan","userId":"12247996726828990634"}},"outputId":"f79ea269-f997-4a0f-e0ea-bc85990ae729"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/tmp/tmpuvdsohoe/5f855cf5-88e3-4e0c-85a6-aa29e2672caf.out starting reduction at device 0: Tesla T4     with array size 16777216  grid 32768 block 512\n","gpu Unrolling8  elapsed 0.000320 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n","gpu Unrolling16 elapsed 0.000294 sec gpu_sum: 2139353471 <<<grid 2048 block 512>>>\n","reduceUnrolling16 has the least execution time.\n","\n"]}]},{"cell_type":"markdown","source":["8"],"metadata":{"id":"H-NlhLb4aIHs"}},{"cell_type":"code","source":["%%cu\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include <cuda.h>\n","#include <sys/time.h>\n","\n","__global__ void reduceUnrolling8 (int *g_idata, int *g_odata, unsigned int n)\n","{\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n","\n","    // unrolling 8\n","    if (idx + 7 * blockDim.x < n)\n","    {\n","        int a1 = g_idata[idx];\n","        int a2 = g_idata[idx + blockDim.x];\n","        int a3 = g_idata[idx + 2 * blockDim.x];\n","        int a4 = g_idata[idx + 3 * blockDim.x];\n","        int b1 = g_idata[idx + 4 * blockDim.x];\n","        int b2 = g_idata[idx + 5 * blockDim.x];\n","        int b3 = g_idata[idx + 6 * blockDim.x];\n","        int b4 = g_idata[idx + 7 * blockDim.x];\n","        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n","    }\n","\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n","    {\n","        if (tid < stride)\n","        {\n","            idata[tid] += idata[tid + stride];\n","        }\n","\n","        // synchronize within threadblock\n","        __syncthreads();\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n","}\n","\n","#ifndef _COMMON_H\n","#define _COMMON_H\n","\n","#define CHECK(call)                                                            \\\n","{                                                                              \\\n","    const cudaError_t error = call;                                            \\\n","    if (error != cudaSuccess)                                                  \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n","        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n","                cudaGetErrorString(error));                                    \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUBLAS(call)                                                     \\\n","{                                                                              \\\n","    cublasStatus_t err;                                                        \\\n","    if ((err = (call)) != CUBLAS_STATUS_SUCCESS)                               \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CUBLAS error %d at %s:%d\\n\", err, __FILE__,       \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CURAND(call)                                                     \\\n","{                                                                              \\\n","    curandStatus_t err;                                                        \\\n","    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUFFT(call)                                                      \\\n","{                                                                              \\\n","    cufftResult err;                                                           \\\n","    if ( (err = (call)) != CUFFT_SUCCESS)                                      \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CUFFT error %d at %s:%d\\n\", err, __FILE__,        \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUSPARSE(call)                                                   \\\n","{                                                                              \\\n","    cusparseStatus_t err;                                                      \\\n","    if ((err = (call)) != CUSPARSE_STATUS_SUCCESS)                             \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got error %d at %s:%d\\n\", err, __FILE__, __LINE__);   \\\n","        cudaError_t cuda_err = cudaGetLastError();                             \\\n","        if (cuda_err != cudaSuccess)                                           \\\n","        {                                                                      \\\n","            fprintf(stderr, \"  CUDA error \\\"%s\\\" also detected\\n\",             \\\n","                    cudaGetErrorString(cuda_err));                             \\\n","        }                                                                      \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","inline double seconds()\n","{\n","    struct timeval tp;\n","    struct timezone tzp;\n","    int i = gettimeofday(&tp, &tzp);\n","    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n","}\n","\n","#endif // _COMMON_H\n","\n","int main(int argc, char **argv)\n","{\n","    // set up device\n","    int dev = 0;\n","    cudaDeviceProp deviceProp;\n","    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","    printf(\"%s starting reduction at \", argv[0]);\n","    printf(\"device %d: %s \", dev, deviceProp.name);\n","    CHECK(cudaSetDevice(dev));\n","\n","    bool bResult = false;\n","\n","    // initialization\n","    int size = 1 << 24; // total number of elements to reduce\n","    printf(\"    with array size %d  \", size);\n","\n","    // execution configuration\n","    int blocksize = 512;   // initial block size\n","\n","    if(argc > 1)\n","    {\n","        blocksize = atoi(argv[1]);   // block size from command line argument\n","    }\n","\n","    dim3 block (blocksize, 1);\n","    dim3 grid  ((size + block.x - 1) / block.x, 1);\n","    printf(\"grid %d block %d\\n\", grid.x, block.x);\n","\n","    // allocate host memory\n","    size_t bytes = size * sizeof(int);\n","    int *h_idata = (int *) malloc(bytes);\n","    int *h_odata = (int *) malloc(grid.x * sizeof(int));\n","    int *tmp     = (int *) malloc(bytes);\n","\n","    // initialize the array\n","    for (int i = 0; i < size; i++)\n","    {\n","        // mask off high 2 bytes to force max number to 255\n","        h_idata[i] = (int)( rand() & 0xFF );\n","    }\n","\n","    memcpy (tmp, h_idata, bytes);\n","\n","    double iStart, iElapsunroll8,iElapsunroll16;\n","    int gpu_sum = 0;\n","\n","    // allocate device memory\n","    int *d_idata = NULL;\n","    int *d_odata = NULL;\n","    CHECK(cudaMalloc((void **) &d_idata, bytes));\n","    CHECK(cudaMalloc((void **) &d_odata, grid.x * sizeof(int)));\n","\n","    // kernel 1: reduceUnrolling8\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    CHECK(cudaDeviceSynchronize());\n","    iStart = seconds();\n","    reduceUnrolling8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaDeviceSynchronize());\n","    iElapsunroll8 = seconds() - iStart;\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"gpu Unrolling8  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n","           \"%d>>>\\n\", iElapsunroll8, gpu_sum, grid.x / 8, block.x);\n","\n","    // Determine the kernel with the least execution time\n","\n","    // free host memory\n","    free(h_idata);\n","    free(h_odata);\n","    // free device memory\n","    CHECK(cudaFree(d_idata));\n","    CHECK(cudaFree(d_odata));\n","    // reset device\n","    CHECK(cudaDeviceReset());\n","    return EXIT_SUCCESS;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKutyHkJYsiY","executionInfo":{"status":"ok","timestamp":1701350725299,"user_tz":-330,"elapsed":2545,"user":{"displayName":"Venkatesh Elangovan","userId":"12247996726828990634"}},"outputId":"1b8e28bd-a347-4feb-8c42-f82f1499fb85"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/tmp/tmp2jht905m/593eb7a3-2d38-4262-b9c5-cd19a9d4b6aa.out starting reduction at device 0: Tesla T4     with array size 16777216  grid 32768 block 512\n","gpu Unrolling8  elapsed 0.000328 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n","\n"]}]},{"cell_type":"markdown","source":["16"],"metadata":{"id":"4EPTpaseaKqV"}},{"cell_type":"code","source":["%%cu\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include <cuda.h>\n","#include <sys/time.h>\n","\n","\n","__global__ void reduceUnrolling16 (int *g_idata, int *g_odata, unsigned int n)\n","{\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    unsigned int idx = blockIdx.x * blockDim.x * 16 + threadIdx.x;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x * 16;\n","\n","    // unrolling 16\n","    if (idx + 15 * blockDim.x < n)\n","    {\n","        int a1 = g_idata[idx];\n","        int a2 = g_idata[idx + blockDim.x];\n","        int a3 = g_idata[idx + 2 * blockDim.x];\n","        int a4 = g_idata[idx + 3 * blockDim.x];\n","        int b1 = g_idata[idx + 4 * blockDim.x];\n","        int b2 = g_idata[idx + 5 * blockDim.x];\n","        int b3 = g_idata[idx + 6 * blockDim.x];\n","        int b4 = g_idata[idx + 7 * blockDim.x];\n","        int c1 = g_idata[idx + 8 * blockDim.x];\n","        int c2 = g_idata[idx + 9 * blockDim.x];\n","        int c3 = g_idata[idx + 10 * blockDim.x];\n","        int c4 = g_idata[idx + 11 * blockDim.x];\n","        int d1 = g_idata[idx + 12 * blockDim.x];\n","        int d2 = g_idata[idx + 13 * blockDim.x];\n","        int d3 = g_idata[idx + 14 * blockDim.x];\n","        int d4 = g_idata[idx + 15 * blockDim.x];\n","        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4 + c1 + c2 + c3 + c4\n","                       + d1 + d2 + d3 + d4;\n","    }\n","\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n","    {\n","        if (tid < stride)\n","        {\n","            idata[tid] += idata[tid + stride];\n","        }\n","\n","        // synchronize within threadblock\n","        __syncthreads();\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n","}\n","\n","#ifndef _COMMON_H\n","#define _COMMON_H\n","\n","#define CHECK(call)                                                            \\\n","{                                                                              \\\n","    const cudaError_t error = call;                                            \\\n","    if (error != cudaSuccess)                                                  \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n","        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n","                cudaGetErrorString(error));                                    \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUBLAS(call)                                                     \\\n","{                                                                              \\\n","    cublasStatus_t err;                                                        \\\n","    if ((err = (call)) != CUBLAS_STATUS_SUCCESS)                               \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CUBLAS error %d at %s:%d\\n\", err, __FILE__,       \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CURAND(call)                                                     \\\n","{                                                                              \\\n","    curandStatus_t err;                                                        \\\n","    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUFFT(call)                                                      \\\n","{                                                                              \\\n","    cufftResult err;                                                           \\\n","    if ( (err = (call)) != CUFFT_SUCCESS)                                      \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got CUFFT error %d at %s:%d\\n\", err, __FILE__,        \\\n","                __LINE__);                                                     \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","#define CHECK_CUSPARSE(call)                                                   \\\n","{                                                                              \\\n","    cusparseStatus_t err;                                                      \\\n","    if ((err = (call)) != CUSPARSE_STATUS_SUCCESS)                             \\\n","    {                                                                          \\\n","        fprintf(stderr, \"Got error %d at %s:%d\\n\", err, __FILE__, __LINE__);   \\\n","        cudaError_t cuda_err = cudaGetLastError();                             \\\n","        if (cuda_err != cudaSuccess)                                           \\\n","        {                                                                      \\\n","            fprintf(stderr, \"  CUDA error \\\"%s\\\" also detected\\n\",             \\\n","                    cudaGetErrorString(cuda_err));                             \\\n","        }                                                                      \\\n","        exit(1);                                                               \\\n","    }                                                                          \\\n","}\n","\n","inline double seconds()\n","{\n","    struct timeval tp;\n","    struct timezone tzp;\n","    int i = gettimeofday(&tp, &tzp);\n","    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n","}\n","\n","#endif // _COMMON_H\n","\n","int main(int argc, char **argv)\n","{\n","    // set up device\n","    int dev = 0;\n","    cudaDeviceProp deviceProp;\n","    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","    printf(\"%s starting reduction at \", argv[0]);\n","    printf(\"device %d: %s \", dev, deviceProp.name);\n","    CHECK(cudaSetDevice(dev));\n","\n","    bool bResult = false;\n","\n","    // initialization\n","    int size = 1 << 24; // total number of elements to reduce\n","    printf(\"    with array size %d  \", size);\n","\n","    // execution configuration\n","    int blocksize = 512;   // initial block size\n","\n","    if(argc > 1)\n","    {\n","        blocksize = atoi(argv[1]);   // block size from command line argument\n","    }\n","\n","    dim3 block (blocksize, 1);\n","    dim3 grid  ((size + block.x - 1) / block.x, 1);\n","    printf(\"grid %d block %d\\n\", grid.x, block.x);\n","\n","    // allocate host memory\n","    size_t bytes = size * sizeof(int);\n","    int *h_idata = (int *) malloc(bytes);\n","    int *h_odata = (int *) malloc(grid.x * sizeof(int));\n","    int *tmp     = (int *) malloc(bytes);\n","\n","    // initialize the array\n","    for (int i = 0; i < size; i++)\n","    {\n","        // mask off high 2 bytes to force max number to 255\n","        h_idata[i] = (int)( rand() & 0xFF );\n","    }\n","\n","    memcpy (tmp, h_idata, bytes);\n","\n","    double iStart, iElapsunroll8,iElapsunroll16;\n","    int gpu_sum = 0;\n","\n","    // allocate device memory\n","    int *d_idata = NULL;\n","    int *d_odata = NULL;\n","    CHECK(cudaMalloc((void **) &d_idata, bytes));\n","    CHECK(cudaMalloc((void **) &d_odata, grid.x * sizeof(int)));\n","\n","    for (int i = 0; i < grid.x / 16; i++) gpu_sum += h_odata[i];\n","// kernel 2: reduceUnrolling16\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    CHECK(cudaDeviceSynchronize());\n","    iStart = seconds();\n","    reduceUnrolling16<<<grid.x / 16, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaDeviceSynchronize());\n","    iElapsunroll16 = seconds() - iStart;\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 16 * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x / 16; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"gpu Unrolling16 elapsed %f sec gpu_sum: %d <<<grid %d block \"\n","           \"%d>>>\\n\", iElapsunroll16, gpu_sum, grid.x / 16, block.x);\n","\n","    // Determine the kernel with the least execution time\n","\n","    // free host memory\n","    free(h_idata);\n","    free(h_odata);\n","    // free device memory\n","    CHECK(cudaFree(d_idata));\n","    CHECK(cudaFree(d_odata));\n","    // reset device\n","    CHECK(cudaDeviceReset());\n","    return EXIT_SUCCESS;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOYgNjl5Zzhv","executionInfo":{"status":"ok","timestamp":1701350828534,"user_tz":-330,"elapsed":890,"user":{"displayName":"Venkatesh Elangovan","userId":"12247996726828990634"}},"outputId":"78290ec0-ebb2-447e-9577-172808442616"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/tmp/tmphxpyvo09/428048c8-39cd-4859-87a3-f811729f7c49.out starting reduction at device 0: Tesla T4     with array size 16777216  grid 32768 block 512\n","gpu Unrolling16 elapsed 0.000306 sec gpu_sum: 2139353471 <<<grid 2048 block 512>>>\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Gp9v1qjsaV5X"},"execution_count":null,"outputs":[]}]}